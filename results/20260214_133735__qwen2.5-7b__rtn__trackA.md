# 实验结果: qwen2.5-7b + rtn (Track A)

## 运行信息

- **运行时间**: 2026-02-14T13:37:35.674317
- **脚本**: `scripts/run_one.py`
- **完整 CLI 参数**:
  ```
  scripts/run_one.py --model qwen2.5-7b --method rtn --track A
  ```

## 数据集

- **校准数据集**: N/A
- **校准样本数**: N/A
- **校准序列长度**: N/A
- **PPL 评测数据集**: 
- **lm-eval 任务**: 

## 量化参数

- **方法**: rtn
- **赛道**: Track A
- **weight**: {"w_bits": 4, "group_size": 128, "granularity": "per_group", "scheme": "symmetric"}
- **Seed**: 42

## PPL 结果

| 数据集 | PPL | NLL |
|--------|-----|-----|
| wikitext2 | 7.2676 | 1.983425 |

## lm-eval 任务结果

| 任务 | 指标 | 分数 |
|------|------|------|
| arc_challenge | alias | arc_challenge |
| arc_challenge | acc,none | 0.4599 |
| arc_challenge | acc_stderr,none | 0.0146 |
| arc_challenge | acc_norm,none | 0.4846 |
| arc_challenge | acc_norm_stderr,none | 0.0146 |
| arc_easy | alias | arc_easy |
| arc_easy | acc,none | 0.7778 |
| arc_easy | acc_stderr,none | 0.0085 |
| arc_easy | acc_norm,none | 0.7382 |
| arc_easy | acc_norm_stderr,none | 0.009 |
| gsm8k | alias | gsm8k |
| gsm8k | exact_match,strict-match | 0.7081 |
| gsm8k | exact_match_stderr,strict-match | 0.0125 |
| gsm8k | exact_match,flexible-extract | 0.7111 |
| gsm8k | exact_match_stderr,flexible-extract | 0.0125 |
| hellaswag | alias | hellaswag |
| hellaswag | acc,none | 0.5637 |
| hellaswag | acc_stderr,none | 0.0049 |
| hellaswag | acc_norm,none | 0.7698 |
| hellaswag | acc_norm_stderr,none | 0.0042 |
| mmlu | acc,none | 0.6911 |
| mmlu | acc_stderr,none | 0.0037 |
| mmlu | alias | mmlu |
| mmlu_humanities | acc,none | 0.6045 |
| mmlu_humanities | acc_stderr,none | 0.0065 |
| mmlu_humanities | alias |  - humanities |
| mmlu_formal_logic | alias |   - formal_logic |
| mmlu_formal_logic | acc,none | 0.5 |
| mmlu_formal_logic | acc_stderr,none | 0.0447 |
| mmlu_high_school_european_history | alias |   - high_school_european_history |
| mmlu_high_school_european_history | acc,none | 0.8364 |
| mmlu_high_school_european_history | acc_stderr,none | 0.0289 |
| mmlu_high_school_us_history | alias |   - high_school_us_history |
| mmlu_high_school_us_history | acc,none | 0.8578 |
| mmlu_high_school_us_history | acc_stderr,none | 0.0245 |
| mmlu_high_school_world_history | alias |   - high_school_world_history |
| mmlu_high_school_world_history | acc,none | 0.865 |
| mmlu_high_school_world_history | acc_stderr,none | 0.0222 |
| mmlu_international_law | alias |   - international_law |
| mmlu_international_law | acc,none | 0.8678 |
| mmlu_international_law | acc_stderr,none | 0.0309 |
| mmlu_jurisprudence | alias |   - jurisprudence |
| mmlu_jurisprudence | acc,none | 0.8426 |
| mmlu_jurisprudence | acc_stderr,none | 0.0352 |
| mmlu_logical_fallacies | alias |   - logical_fallacies |
| mmlu_logical_fallacies | acc,none | 0.8098 |
| mmlu_logical_fallacies | acc_stderr,none | 0.0308 |
| mmlu_moral_disputes | alias |   - moral_disputes |
| mmlu_moral_disputes | acc,none | 0.7601 |
| mmlu_moral_disputes | acc_stderr,none | 0.023 |
| mmlu_moral_scenarios | alias |   - moral_scenarios |
| mmlu_moral_scenarios | acc,none | 0.3374 |
| mmlu_moral_scenarios | acc_stderr,none | 0.0158 |
| mmlu_philosophy | alias |   - philosophy |
| mmlu_philosophy | acc,none | 0.7203 |
| mmlu_philosophy | acc_stderr,none | 0.0255 |
| mmlu_prehistory | alias |   - prehistory |
| mmlu_prehistory | acc,none | 0.8086 |
| mmlu_prehistory | acc_stderr,none | 0.0219 |
| mmlu_professional_law | alias |   - professional_law |
| mmlu_professional_law | acc,none | 0.4824 |
| mmlu_professional_law | acc_stderr,none | 0.0128 |
| mmlu_world_religions | alias |   - world_religions |
| mmlu_world_religions | acc,none | 0.8421 |
| mmlu_world_religions | acc_stderr,none | 0.028 |
| mmlu_other | acc,none | 0.7499 |
| mmlu_other | acc_stderr,none | 0.0075 |
| mmlu_other | alias |  - other |
| mmlu_business_ethics | alias |   - business_ethics |
| mmlu_business_ethics | acc,none | 0.73 |
| mmlu_business_ethics | acc_stderr,none | 0.0446 |
| mmlu_clinical_knowledge | alias |   - clinical_knowledge |
| mmlu_clinical_knowledge | acc,none | 0.7962 |
| mmlu_clinical_knowledge | acc_stderr,none | 0.0248 |
| mmlu_college_medicine | alias |   - college_medicine |
| mmlu_college_medicine | acc,none | 0.6821 |
| mmlu_college_medicine | acc_stderr,none | 0.0355 |
| mmlu_global_facts | alias |   - global_facts |
| mmlu_global_facts | acc,none | 0.5 |
| mmlu_global_facts | acc_stderr,none | 0.0503 |
| mmlu_human_aging | alias |   - human_aging |
| mmlu_human_aging | acc,none | 0.7265 |
| mmlu_human_aging | acc_stderr,none | 0.0299 |
| mmlu_management | alias |   - management |
| mmlu_management | acc,none | 0.8835 |
| mmlu_management | acc_stderr,none | 0.0318 |
| mmlu_marketing | alias |   - marketing |
| mmlu_marketing | acc,none | 0.8974 |
| mmlu_marketing | acc_stderr,none | 0.0199 |
| mmlu_medical_genetics | alias |   - medical_genetics |
| mmlu_medical_genetics | acc,none | 0.86 |
| mmlu_medical_genetics | acc_stderr,none | 0.0349 |
| mmlu_miscellaneous | alias |   - miscellaneous |
| mmlu_miscellaneous | acc,none | 0.8378 |
| mmlu_miscellaneous | acc_stderr,none | 0.0132 |
| mmlu_nutrition | alias |   - nutrition |
| mmlu_nutrition | acc,none | 0.7778 |
| mmlu_nutrition | acc_stderr,none | 0.0238 |
| mmlu_professional_accounting | alias |   - professional_accounting |
| mmlu_professional_accounting | acc,none | 0.5603 |
| mmlu_professional_accounting | acc_stderr,none | 0.0296 |
| mmlu_professional_medicine | alias |   - professional_medicine |
| mmlu_professional_medicine | acc,none | 0.6949 |
| mmlu_professional_medicine | acc_stderr,none | 0.028 |
| mmlu_virology | alias |   - virology |
| mmlu_virology | acc,none | 0.5301 |
| mmlu_virology | acc_stderr,none | 0.0389 |
| mmlu_social_sciences | acc,none | 0.7975 |
| mmlu_social_sciences | acc_stderr,none | 0.0071 |
| mmlu_social_sciences | alias |  - social sciences |
| mmlu_econometrics | alias |   - econometrics |
| mmlu_econometrics | acc,none | 0.6053 |
| mmlu_econometrics | acc_stderr,none | 0.046 |
| mmlu_high_school_geography | alias |   - high_school_geography |
| mmlu_high_school_geography | acc,none | 0.8687 |
| mmlu_high_school_geography | acc_stderr,none | 0.0241 |
| mmlu_high_school_government_and_politics | alias |   - high_school_government_and_politics |
| mmlu_high_school_government_and_politics | acc,none | 0.9171 |
| mmlu_high_school_government_and_politics | acc_stderr,none | 0.0199 |
| mmlu_high_school_macroeconomics | alias |   - high_school_macroeconomics |
| mmlu_high_school_macroeconomics | acc,none | 0.7615 |
| mmlu_high_school_macroeconomics | acc_stderr,none | 0.0216 |
| mmlu_high_school_microeconomics | alias |   - high_school_microeconomics |
| mmlu_high_school_microeconomics | acc,none | 0.8487 |
| mmlu_high_school_microeconomics | acc_stderr,none | 0.0233 |
| mmlu_high_school_psychology | alias |   - high_school_psychology |
| mmlu_high_school_psychology | acc,none | 0.8697 |
| mmlu_high_school_psychology | acc_stderr,none | 0.0144 |
| mmlu_human_sexuality | alias |   - human_sexuality |
| mmlu_human_sexuality | acc,none | 0.771 |
| mmlu_human_sexuality | acc_stderr,none | 0.0369 |
| mmlu_professional_psychology | alias |   - professional_psychology |
| mmlu_professional_psychology | acc,none | 0.732 |
| mmlu_professional_psychology | acc_stderr,none | 0.0179 |
| mmlu_public_relations | alias |   - public_relations |
| mmlu_public_relations | acc,none | 0.6455 |
| mmlu_public_relations | acc_stderr,none | 0.0458 |
| mmlu_security_studies | alias |   - security_studies |
| mmlu_security_studies | acc,none | 0.7796 |
| mmlu_security_studies | acc_stderr,none | 0.0265 |
| mmlu_sociology | alias |   - sociology |
| mmlu_sociology | acc,none | 0.8209 |
| mmlu_sociology | acc_stderr,none | 0.0271 |
| mmlu_us_foreign_policy | alias |   - us_foreign_policy |
| mmlu_us_foreign_policy | acc,none | 0.87 |
| mmlu_us_foreign_policy | acc_stderr,none | 0.0338 |
| mmlu_stem | acc,none | 0.6587 |
| mmlu_stem | acc_stderr,none | 0.0082 |
| mmlu_stem | alias |  - stem |
| mmlu_abstract_algebra | alias |   - abstract_algebra |
| mmlu_abstract_algebra | acc,none | 0.46 |
| mmlu_abstract_algebra | acc_stderr,none | 0.0501 |
| mmlu_anatomy | alias |   - anatomy |
| mmlu_anatomy | acc,none | 0.7259 |
| mmlu_anatomy | acc_stderr,none | 0.0385 |
| mmlu_astronomy | alias |   - astronomy |
| mmlu_astronomy | acc,none | 0.8289 |
| mmlu_astronomy | acc_stderr,none | 0.0306 |
| mmlu_college_biology | alias |   - college_biology |
| mmlu_college_biology | acc,none | 0.8056 |
| mmlu_college_biology | acc_stderr,none | 0.0331 |
| mmlu_college_chemistry | alias |   - college_chemistry |
| mmlu_college_chemistry | acc,none | 0.46 |
| mmlu_college_chemistry | acc_stderr,none | 0.0501 |
| mmlu_college_computer_science | alias |   - college_computer_science |
| mmlu_college_computer_science | acc,none | 0.64 |
| mmlu_college_computer_science | acc_stderr,none | 0.0482 |
| mmlu_college_mathematics | alias |   - college_mathematics |
| mmlu_college_mathematics | acc,none | 0.43 |
| mmlu_college_mathematics | acc_stderr,none | 0.0498 |
| mmlu_college_physics | alias |   - college_physics |
| mmlu_college_physics | acc,none | 0.5098 |
| mmlu_college_physics | acc_stderr,none | 0.0497 |
| mmlu_computer_security | alias |   - computer_security |
| mmlu_computer_security | acc,none | 0.83 |
| mmlu_computer_security | acc_stderr,none | 0.0378 |
| mmlu_conceptual_physics | alias |   - conceptual_physics |
| mmlu_conceptual_physics | acc,none | 0.6809 |
| mmlu_conceptual_physics | acc_stderr,none | 0.0305 |
| mmlu_electrical_engineering | alias |   - electrical_engineering |
| mmlu_electrical_engineering | acc,none | 0.6897 |
| mmlu_electrical_engineering | acc_stderr,none | 0.0386 |
| mmlu_elementary_mathematics | alias |   - elementary_mathematics |
| mmlu_elementary_mathematics | acc,none | 0.6429 |
| mmlu_elementary_mathematics | acc_stderr,none | 0.0247 |
| mmlu_high_school_biology | alias |   - high_school_biology |
| mmlu_high_school_biology | acc,none | 0.829 |
| mmlu_high_school_biology | acc_stderr,none | 0.0214 |
| mmlu_high_school_chemistry | alias |   - high_school_chemistry |
| mmlu_high_school_chemistry | acc,none | 0.6355 |
| mmlu_high_school_chemistry | acc_stderr,none | 0.0339 |
| mmlu_high_school_computer_science | alias |   - high_school_computer_science |
| mmlu_high_school_computer_science | acc,none | 0.82 |
| mmlu_high_school_computer_science | acc_stderr,none | 0.0386 |
| mmlu_high_school_mathematics | alias |   - high_school_mathematics |
| mmlu_high_school_mathematics | acc,none | 0.5444 |
| mmlu_high_school_mathematics | acc_stderr,none | 0.0304 |
| mmlu_high_school_physics | alias |   - high_school_physics |
| mmlu_high_school_physics | acc,none | 0.5629 |
| mmlu_high_school_physics | acc_stderr,none | 0.0405 |
| mmlu_high_school_statistics | alias |   - high_school_statistics |
| mmlu_high_school_statistics | acc,none | 0.6481 |
| mmlu_high_school_statistics | acc_stderr,none | 0.0326 |
| mmlu_machine_learning | alias |   - machine_learning |
| mmlu_machine_learning | acc,none | 0.5357 |
| mmlu_machine_learning | acc_stderr,none | 0.0473 |
| piqa | alias | piqa |
| piqa | acc,none | 0.7802 |
| piqa | acc_stderr,none | 0.0097 |
| piqa | acc_norm,none | 0.7813 |
| piqa | acc_norm_stderr,none | 0.0096 |
| winogrande | alias | winogrande |
| winogrande | acc,none | 0.6961 |
| winogrande | acc_stderr,none | 0.0129 |

**平均准确率**: 0.7098

## 系统指标

- **VRAM 峰值**: 21822.4 MB
- **评测总耗时**: 5171.6 秒

## 运行环境

- **时间**: 2026-02-14T13:37:35.649159
- **主机**: sev-cxl
- **OS**: Linux 6.11.0-snp-host-68799c0277b2
- **Python**: 3.13.11 | packaged by Anaconda, Inc. | (main, Dec 10 2025, 21:28:48) [GCC 14.3.0]
- **GPU 0**: NVIDIA H200 NVL (143771 MB)
- **Driver**: 580.95.05
- **CUDA**: 12.8
- **cuDNN**: 91002

### 关键包版本

- `torch`: 2.10.0+cu128
- `transformers`: 5.1.0
- `datasets`: 4.5.0
- `accelerate`: 1.12.0
- `lm-eval`: 0.4.11
- `safetensors`: 0.7.0
- `tokenizers`: 0.22.2
- `scipy`: 1.17.0
- `numpy`: 2.4.2
