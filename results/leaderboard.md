# PTQ Benchmark Leaderboard

---

## Track A: Weight-Only Quantization (W4A16)

> **模型**: Qwen2.5-7B | **硬件**: H200 NVL 141GB

| 排名 | 方法 | PPL (WikiText-2) ↓ | Avg Accuracy ↑ | PPL 退化 | Acc 退化 | VRAM (MB) | 量化耗时 |
|:----:|------|:-------------------:|:--------------:|:--------:|:--------:|:---------:|:--------:|
| 🥇 | **FP16** (baseline) | **6.16** | **0.7351** | — | — | 18,367 | — |
| 🥈 | **AWQ** (W4, pre-quantized) | **6.91** | **0.7233** | +0.75 | -1.18% | 19,891 | 5.6s |
| 🥉 | **RTN** (W4, per-group sym) | **7.27** | **0.7098** | +1.11 | -2.53% | 21,822 | 0.1s |
| ⛔ | **GPTQ** (blocked) | — | — | — | — | — | — |

---

## Track C: KV Cache Compression — 多梯度 Passkey Retrieval 对比

> **模型**: Qwen2.5-7B | **硬件**: H200 NVL 141GB | **日期**: 2026-02-17
>
> 10 个随机 5 位密钥 × 4 个深度 (10%, 25%, 50%, 75%) = 每格 40 次测试

### 核心结果表

| 条件 | Context | Residual | **FP16** | **KIVI** (INT2) | **KVQuant** (INT2+outlier) | **FORGE** (SVD) |
|------|:-------:|:--------:|:--------:|:---:|:---:|:---:|
| 温和 | 2K | 128 | **100%** | 45% | 72% | 0% |
| 中等 | 2K | 32 | **100%** | 32% | 68% | 0% |
| 温和+长 | 4K | 128 | **100%** | 22% | 38% | 0% |
| 中等+长 | 4K | 32 | **100%** | 38% | 35% | 0% |
| 中偏激进 | 8K | 64 | **100%** | 10% | 28% | — |
| 激进 | 8K | 32 | **100%** | 5% | 42% | — |
| 很激进 | 8K | 16 | **100%** | 0% | 35% | — |
| 极端 | 16K | 4 | **100%** | 0% | 10% | 0% |

> FORGE 在 8K+ 跳过 (SVD 计算开销过大)。

### 按深度分析 (8K context, residual=32)

| 方法 | 深度 10% | 深度 25% | 深度 50% | 深度 75% |
|------|:--------:|:--------:|:--------:|:--------:|
| **FP16** | 100% | 100% | 100% | 100% |
| **KIVI** | 0% | 10% | 10% | 0% |
| **KVQuant** | 20% | 50% | 60% | 40% |

---

## Track C 分析

### 方法排名

| 排名 | 方法 | 最佳 Passkey (2K/128) | 最差 Passkey (16K/4) | 特点 |
|:----:|------|:------:|:------:|------|
| 🥇 | **FP16** | 100% | 100% | Baseline |
| 🥈 | **KVQuant** | 72% | 10% | Outlier 隔离显著帮助 |
| 🥉 | **KIVI** | 45% | 0% | 纯 INT2，误差积累快 |
| ⛔ | **FORGE** | 0% | 0% | SVD 完全丢失精确信息 |

### 关键发现

1. **即使最温和条件 (2K/128)，INT2 量化也会退化**
   - KIVI 45%, KVQuant 72%, 远非无损
   - 旧实验显示 "无损" 是因为量化代码从未执行 (bug)

2. **KVQuant outlier 隔离显著有效**
   - 在所有条件下均优于 KIVI (平均高 ~25%)
   - 每个 token 隔离 1 个最大 outlier 就能大幅减少量化误差

3. **FORGE SVD 完全不适合精确检索任务**
   - 所有条件下 0% — SVD 低秩近似必然丢失高频细节
   - 但 SVD 可能在语义连贯性任务上表现更好 (待测)

4. **Context 越长，退化越明显**
   - KIVI: 2K→45%, 4K→22%, 8K→5%
   - 量化历史占比越大，累积误差越严重

5. **Bug 修复说明**
   - 之前所有方法与 FP16 完全一致是因为 transformers v5.x API 变更
   - Attention 不再通过 `outputs[2]` 返回 KV States
   - 修复: 子类化 `DynamicLayer`，覆写 `update()` 拦截 KV

---

## 环境信息

| 项目 | 版本 |
|------|------|
| GPU | NVIDIA H200 NVL 141GB |
| PyTorch | 2.10.0+cu128 |
| Transformers | 5.1.0 |
| lm-eval | 0.4.11 |
| Python | 3.13 |
