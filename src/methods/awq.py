# -*- coding: utf-8 -*-
"""
AWQ â€” Activation-aware Weight Quantization

åŠ è½½ HuggingFace Hub ä¸Šçš„é¢„é‡åŒ– AWQ æ¨¡å‹è¿›è¡Œè¯„æµ‹ã€‚
ä½¿ç”¨ autoawq çš„ from_quantized() åŠ è½½é¢„é‡åŒ–æ¨¡å‹ã€‚
"""

from src.registry import register
from src.methods.base import BaseQuantMethod
from typing import Any


@register("awq")
class AWQMethod(BaseQuantMethod):
    """
    AWQ é‡åŒ–æ–¹æ³• wrapperã€‚

    ä½¿ç”¨ autoawq çš„ from_quantized() åŠ è½½é¢„é‡åŒ– AWQ æ¨¡å‹ã€‚
    """

    supported_tracks = ["A"]

    def quantize(self, model: Any, tokenizer: Any, calib_data: Any | None = None) -> Any:
        """
        åŠ è½½é¢„é‡åŒ–çš„ AWQ æ¨¡å‹ã€‚

        å‚æ•°:
            model: åŸå§‹æ¨¡å‹ï¼ˆå°†è¢«é‡Šæ”¾ï¼‰
            tokenizer: tokenizer
            calib_data: æ ¡å‡†æ•°æ®ï¼ˆé¢„é‡åŒ–æ¨¡å‹ä¸éœ€è¦ï¼‰

        è¿”å›:
            Any: é¢„é‡åŒ–çš„ AWQ æ¨¡å‹
        """
        import torch
        from awq import AutoAWQForCausalLM

        model_id = self.config.get("model", {}).get("model_id", "")
        pretrained_quant = self.config.get("model", {}).get("pretrained_quant_models", {})
        awq_model_id = pretrained_quant.get("awq", model_id + "-AWQ")

        cache_dir = self.config.get("paths", {}).get("model_cache_dir", None)
        trust_remote_code = self.config.get("model", {}).get("trust_remote_code", False)

        print(f"ğŸ“‹ AWQ: åŠ è½½é¢„é‡åŒ–æ¨¡å‹: {awq_model_id}")

        # é‡Šæ”¾åŸå§‹æ¨¡å‹
        del model
        torch.cuda.empty_cache()

        # ä½¿ç”¨ autoawq çš„ from_quantized åŠ è½½
        awq_model = AutoAWQForCausalLM.from_quantized(
            awq_model_id,
            fuse_layers=False,
            trust_remote_code=trust_remote_code,
            cache_dir=cache_dir,
        )

        print(f"âœ… AWQ é¢„é‡åŒ–æ¨¡å‹åŠ è½½å®Œæˆ: {awq_model_id}")
        print(f"   å‚æ•°é‡: {sum(p.numel() for p in awq_model.model.parameters()) / 1e9:.2f}B")

        # è¿”å›åº•å±‚çš„ transformers æ¨¡å‹
        return awq_model.model
