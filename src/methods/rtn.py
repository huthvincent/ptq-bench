# -*- coding: utf-8 -*-
"""
RTN (Round-To-Nearest) â€” æœ€ç®€å•çš„æƒé‡é‡åŒ– baseline

ç›´æ¥å¯¹æƒé‡åš per-group round-to-nearest å¯¹ç§°é‡åŒ–ï¼Œ
ä¸ä½¿ç”¨æ ¡å‡†æ•°æ®ä¼˜åŒ–ã€‚è¿™æ˜¯é‡åŒ–çš„æœ€å¼± baselineã€‚

å®ç°æ–¹å¼: æ‰‹åŠ¨å¯¹æ¯ä¸ªçº¿æ€§å±‚çš„æƒé‡åš per-group symmetric é‡åŒ–ã€‚
"""

import torch
from src.registry import register
from src.methods.base import BaseQuantMethod
from typing import Any


def _quantize_tensor_rtn(weight: torch.Tensor, bits: int, group_size: int) -> torch.Tensor:
    """
    å¯¹å•ä¸ªæƒé‡å¼ é‡æ‰§è¡Œ per-group symmetric round-to-nearest é‡åŒ–ã€‚

    å‚æ•°:
        weight: å½¢çŠ¶ [out_features, in_features] çš„æƒé‡
        bits: é‡åŒ–ä½å®½
        group_size: æ¯ç»„çš„å…ƒç´ æ•°

    è¿”å›:
        torch.Tensor: æ¨¡æ‹Ÿé‡åŒ– (simulate quantize) åçš„æƒé‡
    """
    orig_shape = weight.shape
    orig_dtype = weight.dtype

    # å±•å¹³ä¸º [out, in] ç„¶åæŒ‰ group_size åˆ†ç»„
    w = weight.float().reshape(-1, group_size)

    # å¯¹ç§°é‡åŒ–: scale = max(|w|) / (2^(bits-1) - 1)
    qmax = (1 << (bits - 1)) - 1
    scales = w.abs().amax(dim=1, keepdim=True) / qmax
    scales = scales.clamp(min=1e-10)

    # é‡åŒ–å†åé‡åŒ– (simulate quantize)
    w_q = (w / scales).round().clamp(-qmax, qmax)
    w_deq = w_q * scales

    return w_deq.reshape(orig_shape).to(orig_dtype)


@register("rtn")
class RTNMethod(BaseQuantMethod):
    """
    RTN é‡åŒ–æ–¹æ³•ã€‚

    é€šè¿‡æ‰‹åŠ¨å¯¹æ¯ä¸ªçº¿æ€§å±‚æƒé‡åš per-group symmetric round-to-nearest é‡åŒ–ã€‚
    ä¸ä½¿ç”¨æ ¡å‡†æ•°æ®ï¼Œçº¯ç²¹åŸºäºæƒé‡åˆ†å¸ƒæ¥é‡åŒ–ã€‚
    """

    supported_tracks = ["A"]

    def quantize(self, model: Any, tokenizer: Any, calib_data: Any | None = None) -> Any:
        """
        æ‰§è¡Œ RTN é‡åŒ–ã€‚

        éå†æ¨¡å‹æ‰€æœ‰çº¿æ€§å±‚ï¼Œå¯¹æƒé‡åš per-group RTN é‡åŒ–ã€‚
        ä½¿ç”¨ simulate quantize (ä¼ªé‡åŒ–): é‡åŒ–åç«‹å³åé‡åŒ–å› floatã€‚

        å‚æ•°:
            model: åŸå§‹æ¨¡å‹
            tokenizer: tokenizerï¼ˆæœªä½¿ç”¨ï¼‰
            calib_data: æ ¡å‡†æ•°æ®ï¼ˆRTN ä¸ä½¿ç”¨ï¼‰

        è¿”å›:
            Any: ä¼ªé‡åŒ–åçš„æ¨¡å‹
        """
        w_bits = self.config.get("weight", {}).get("w_bits", 4)
        group_size = self.config.get("weight", {}).get("group_size", 128)

        print(f"ğŸ“‹ RTN: W{w_bits} group_size={group_size}")
        print(f"ğŸ“‹ RTN: æ‰‹åŠ¨ per-group symmetric round-to-nearest")

        n_quantized = 0
        n_skipped = 0

        with torch.no_grad():
            for name, module in model.named_modules():
                if isinstance(module, torch.nn.Linear):
                    w = module.weight.data
                    # è·³è¿‡å¤ªå°çš„æƒé‡ (å¦‚ lm_head å¦‚æœ vocab ä¸èƒ½è¢« group_size æ•´é™¤)
                    if w.numel() % group_size != 0:
                        n_skipped += 1
                        continue
                    module.weight.data = _quantize_tensor_rtn(w, w_bits, group_size)
                    n_quantized += 1

        print(f"âœ… RTN é‡åŒ–å®Œæˆ: {n_quantized} ä¸ªçº¿æ€§å±‚é‡åŒ–, {n_skipped} ä¸ªè·³è¿‡")
        return model
